1. privileged things (vector of dynamic)
	1.1 higher judgment functions. the higher judgment function is a quine, and occasionally makes copies of itself. contains many copies of the same command, so that randomness doesn't suddenly run out (we don't want our user to become a Turing machine)
		on new-user event, it runs on the directed judgment function.
		on new-country event, it runs on itself.
	1.2 random judgment. works once per encryption run. copies and mutates judgment functions. 
	1.3 directed judgment/event searcher functions. works like the immune system, many judgments per encryption run. tries to optimize by splitting and duplicating good efforts.
	how do we store information on each of these? every time we copy it, we ought to copy some comments...
		we store 2. if something is going horribly wrong, we revert it.
having few tiers of judgment is good, because the more tiers there are, the harder it is to improve them.
	directed judgement must operate, so each encryption run must consist of several times.
	random judgment must run, so there must be several encryption runs.

everything must have a responsible owner, who is penalized if it goes wrong. for example, if we have language, then the language info must be stored across time.
	however, if immediate judgment fucks it up, it won't really suffer any consequences, because language info isn't tested. same for long-lasting objects like cooperative locks, and circular buffers. judgment can screw it up for speed boosts, and then nobody suffers any consequences.

1. big set of things (vector of dynamic)
	1.1 working functions that directly feed back into judgment. mostly uses 1.3, the goodness indicators
	1.2 working functions. touches everything. a "function unit".
	1.3 goodness indicators (mostly integers)
	1.4, 1.5... mostly integers. sometimes commented integers.
to store comments on things, we use dynamic pointers. the dynamic pointer to the big array stores more dynarrays, which contain the object of interest in the first slot. we don't point to the object directly.

1. we have a directed-judgment function. it randomly gets functions from the big tree of things and then modifies them. it should have some purpose. 
to do this, it picks a function, looks for static-object ASTs, and changes them. but it remembers the old values.
	then it runs the simulation, assigns goodness, and decides to revert or not.
	it creates random functions, and inserts calls to them (fuzztester)
	
there is a huge mess of global integers that are randomly modified. basically, neurotransmitter levels. there are some functions which store constant values into them, some functions which grab some levels and then randomly store into other levels.
	loops should be able to modify their condition somehow, and are under great suspicion.
2. we have a goodness function. somehow, it produces an evaluation of how well you did, and encodes them in some global variables somewhere.
	then, the directed-judgment function uses these special goodness values to do something.
3. random-judgment function.
	randomly changes the goodness function and the directed-judgment function, and itself. also gets values from goodness, to randomly decide its behavior.
	it also makes copies of the directed-judgment function, occasionally kills them.
	these functions ought to be run in parallel.
4. culling function. we don't want memory to explode. so this takes especially useless functions and throws them away.
how do we decide which functions should be called?
	there should be some "reset" functions, that happen when something really bad happens. after a long string of badness, these functions are called.
problem: we can't take in negative feedback, only positive feedback. this is because our changes don't have true negatives, since they're random and arbitrary.

things that are important are repeated many times. just like in DNA.

Function recombination: modification of existing functions. each step is repeated as many times as necessary.
	after each change, we should generally test if the function will still compile. if it won't compile, we must roll-back. roll-back is necessarily baked into the function.
	there are three parts of function changing. the first, is deciding what the new AST is. can be a snipped AST, or a random AST.
	second part is deciding where the new location will be. random ASTs will depend on this step.
	last part is deciding whether to replace or insert.
1. browsing
	1. choose a random function to obtain from, then snip the function by choosing a head, then copying
		INTEGER: size of snip
	2. or, just remember the function, and then use it as a function call.
2. Insertion
	1. in some other function, find some single random spot. we won't allow multiple-AST zeroing for now.
	2. find a snipping location by going down previous_BB pointers. (copy the old AST into the slot. append the new BB to the back). or: (append the new BB to the back, directly).
3. Deletion = substitution. when you make a failure (zero) AST, that's inserted as usual.
4. Substitution. insertion adds in code, but now we have to mix the code to make it interact.
	1. randomly browse the function, memorizing AST locations.
	2. randomly change some AST locations to other ASTs.
	3. randomly load imv values. do some modification to them, by incrementing/decrementing them randomly (this should be passed off to another function)
5. function calling. functions have no way to acquire pointers to globals. thus, we memorize function addresses, and then embed them in nearby functions.
6. global variable creation.
	1. randomly call a function.
	2. insert it as an imv in some other function.

note: when splicing DNA, we can splice from a function to itself.
	and some level of locality is good too.
	for example, with the AST tags, you want to have lots of casework. in that case, ideal splicing involves making lots of if statements, one for each AST tag.
	thus, we splice from a function to itself, and also from functions to nearby functions.

judgment must constantly take in information from the rest of the user.
	for example, when choosing an AST to make, it better outsource this capability.

for ideas that we want to happen, we need to provide meaningful initial implementations. so: values get the old "first value is goodness, second value is information" trick. and then the user regresses on these.
	so the anti-encryption breaker should provide a meaningful correlation, to correlate fields with other fields.
	try to find patterns. if you do find a pattern, immediately duplicate yourself.
		should the duplication be external or internal? external. because otherwise, when modifying, there's potential for cancer.
	and we need to verify that the pattern actually is correctly found. so an external judge will score various different contestants.
basically, here we're testing the judgment function for a single encryption test run (consisting of a single function, and a series of output numbers).
	each judgment function owns a bunch of things.
	and there are many judgment functions for the single encryption test run.

how to stop cancer? probably by limiting the various sources of new things, randomly permuting them, and culling them whenever necessary.

Model:
	1. judgment runs a "testme" AST. this sets up the encryptor, which runs the default runner a lot.
	2. judgment gets to run again after the test suite is done. it compares the time it took to finish the suite. if it's really excessive, then revert.
	3. if performance is worse, then revert.
	4. problem: how do we actually revert? I think we have to snapshot the entire stack.